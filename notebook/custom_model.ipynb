{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAB1Be8N5OzK",
        "outputId": "27a156be-d880-40d0-be78-a1d9883c001e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformers.AdamW (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformers.AdamW\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers.AdamW -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bheIchUt2tQM",
        "outputId": "a0853240-094e-4a68-a82a-020377c44b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Pustaka berhasil diinstal dan diimpor.\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Instalasi dan Impor Pustaka\n",
        "# ------------------------------------------------------------------\n",
        "# Menginstal pustaka yang dibutuhkan.\n",
        "# ------------------------------------------------------------------\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from torch.optim import AdamW\n",
        "import numpy as np\n",
        "\n",
        "print(\"‚úÖ Pustaka berhasil diinstal dan diimpor.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEqsiPCa5G2p",
        "outputId": "3a58c2a4-a5be-48cb-b5f8-aa4bf6cfee5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Menggunakan device: cuda\n",
            "‚úÖ Dataset siap digunakan dengan 136 contoh data.\n"
          ]
        }
      ],
      "source": [
        "#@title 2. Konfigurasi\n",
        "# ------------------------------------------------------------------\n",
        "# Konfigurasi path, nama model, dan parameter training.\n",
        "# ------------------------------------------------------------------\n",
        "# --- Path File ---\n",
        "FINETUNING_DATASET_JSON_FILE = '/content/fintune_data.json'\n",
        "MODEL_SAVE_PATH = '/content/custom_finetuned_model.pth'\n",
        "\n",
        "# --- Model ---\n",
        "BASE_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# --- Parameter Training ---\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# Cek ketersediaan GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Menggunakan device: {device}\")\n",
        "\n",
        "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
        "\n",
        "\n",
        "#@title 3. Persiapan Dataset\n",
        "# ------------------------------------------------------------------\n",
        "# Menyiapkan kelas Dataset PyTorch kustom untuk memuat file\n",
        "# 'fintune_data.json' yang Anda unggah.\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# Pastikan Anda sudah mengunggah file 'fintune_data.json' ke direktori /content/ di Colab.\n",
        "\n",
        "# Kelas Dataset kustom\n",
        "class FineTuningDataset(Dataset):\n",
        "    def __init__(self, dataset_path):\n",
        "        try:\n",
        "            with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "                self.data = json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"üõë Error: File '{dataset_path}' tidak ditemukan. Mohon unggah file tersebut.\")\n",
        "            self.data = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return (item['query'], item['positive_passage'], item['negative_passage'])\n",
        "\n",
        "# Buat instance dataset dan dataloader\n",
        "train_dataset = FineTuningDataset(FINETUNING_DATASET_JSON_FILE)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "\n",
        "if len(train_dataset) > 0:\n",
        "    print(f\"‚úÖ Dataset siap digunakan dengan {len(train_dataset)} contoh data.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dataset kosong. Proses training tidak akan berjalan.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4B6Fj7l9EOB",
        "outputId": "afea5005-1f73-44d4-b6dc-93b12cd3073a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Contoh data dari dataset train:\n",
            "  Contoh 1:\n",
            "    Query: Apa definisi dan peran utama dari Sistem Operasi?\n",
            "    Positive: Sistem Operasi (Operating System/OS) adalah sebuah program atau perangkat lunak yang mengontrol eksekusi aplikasi. [1]\n",
            "OS bertindak sebagai antarmuka (interface) antara pengguna (user) dan perangkat keras (hardware) komputer. [1]\n",
            "OS menyediakan lingkungan di mana pengguna dapat menjalankan program-programnya dengan nyaman dan efisien. [1]\n",
            "    Negative: Selama eksekusinya, sebuah proses dapat berada dalam salah satu dari beberapa status berikut:\n",
            "- New (Baru): Proses sedang dibuat.\n",
            "- Running (Berjalan): Instruksi sedang dieksekusi pada CPU.\n",
            "- Waiting (Menunggu) / Blocked: Proses sedang menunggu suatu event terjadi (misalnya, penyelesaian I/O atau penerimaan sinyal).\n",
            "- Ready (Siap): Proses sedang menunggu untuk dialokasikan ke prosesor oleh scheduler.\n",
            "- Terminated (Selesai): Proses telah selesai dieksekusi.\n",
            "  Contoh 2:\n",
            "    Query: Sebutkan dua tujuan utama dari OS.\n",
            "    Positive: Tujuan utama dari sistem operasi adalah:\n",
            "- **Kenyamanan (Convenience):** Membuat sistem komputer lebih mudah untuk digunakan oleh pengguna. [1]\n",
            "- **Efisiensi (Efficiency):** Memungkinkan penggunaan sumber daya sistem komputer (seperti CPU, memori, perangkat I/O) secara efisien. [1]\n",
            "    Negative: Setiap proses direpresentasikan dalam sistem operasi oleh Process Control Block (PCB), juga dikenal sebagai Task Control Block. PCB berisi banyak informasi yang terkait dengan proses spesifik...\n",
            "  Contoh 3:\n",
            "    Query: Jelaskan peran OS sebagai manajer sumber daya.\n",
            "    Positive: Sebagai 'Manajer Sumber Daya' (Resources Manager):** [4]\n",
            "  OS bertugas mengelola semua sumber daya komputer. Sumber daya ini meliputi prosesor (CPU), memori utama, timer, disk, printer, antarmuka jaringan, dan lainnya. OS memutuskan bagaimana sumber daya ini dialokasikan ke program dan pengguna secara adil dan efisien. [4]\n",
            "    Negative: Sistem operasi dibagi menjadi beberapa lapisan (layer), masing-masing dibangun di atas lapisan yang lebih rendah. Lapisan terbawah adalah perangkat keras; lapisan teratas adalah antarmuka pengguna.\n"
          ]
        }
      ],
      "source": [
        "if len(train_dataset) > 0:\n",
        "    print(\"\\nContoh data dari dataset train:\")\n",
        "    for i in range(min(3, len(train_dataset))):\n",
        "        query, positive, negative = train_dataset[i]\n",
        "        print(f\"  Contoh {i+1}:\")\n",
        "        print(f\"    Query: {query}\")\n",
        "        print(f\"    Positive: {positive}\")\n",
        "        print(f\"    Negative: {negative}\")\n",
        "else:\n",
        "    print(\"\\nDataset train kosong, tidak ada data untuk dicetak.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5VF3eJdD113",
        "outputId": "3e9c52d9-441b-46a6-efc6-0f2a5b02f2fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Memulai proses training (AI Learning)...\n",
            "Epoch 1/5 - Rata-rata Loss: 0.7473\n",
            "Epoch 2/5 - Rata-rata Loss: 0.5912\n",
            "Epoch 3/5 - Rata-rata Loss: 0.4851\n",
            "Epoch 4/5 - Rata-rata Loss: 0.4178\n",
            "Epoch 5/5 - Rata-rata Loss: 0.3760\n",
            "‚úÖ Proses training selesai.\n",
            "üíæ Model yang telah dilatih disimpan di: /content/custom_finetuned_model.pth\n"
          ]
        }
      ],
      "source": [
        "#@title 4. Membangun & Menjalankan Loop Training\n",
        "# ------------------------------------------------------------------\n",
        "if len(train_dataset) > 0:\n",
        "    # 1. Inisialisasi Model, Loss, dan Optimizer\n",
        "    model = SentenceTransformer(BASE_MODEL_NAME).to(device)\n",
        "    loss_function = nn.CosineEmbeddingLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    print(\"üöÄ Memulai proses training (AI Learning)...\")\n",
        "\n",
        "    # 2. Loop Training\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        total_loss = 0\n",
        "        for batch in train_dataloader:\n",
        "            queries, positive_passages, negative_passages = batch\n",
        "\n",
        "            # Reset gradien\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # ---- Mengolah data dan menghitung loss ----\n",
        "            # Siapkan pasangan positif dan negatif dalam satu batch untuk efisiensi\n",
        "            # Mengubah tuple menjadi list agar bisa diproses oleh tokenizer\n",
        "            texts = list(queries) + list(positive_passages) + list(negative_passages)\n",
        "\n",
        "            # Tokenisasi semua teks sekaligus\n",
        "            features = model.tokenize(texts)\n",
        "            # Pindahkan semua tensor hasil tokenisasi ke GPU\n",
        "            for key in features:\n",
        "                features[key] = features[key].to(device)\n",
        "\n",
        "            # Dapatkan semua embedding dengan melewatkan fitur melalui model\n",
        "            # Ini akan menghasilkan embedding yang memiliki gradien\n",
        "            embeddings = model(features)['sentence_embedding']\n",
        "\n",
        "            # Pisahkan kembali embeddingnya sesuai urutan awal\n",
        "            query_emb = embeddings[0:len(queries)]\n",
        "            pos_emb = embeddings[len(queries):len(queries)+len(positive_passages)]\n",
        "            neg_emb = embeddings[len(queries)+len(positive_passages):]\n",
        "\n",
        "            # Hitung loss untuk pasangan positif (target = 1)\n",
        "            positive_loss = loss_function(query_emb, pos_emb, torch.ones(len(queries)).to(device))\n",
        "            # Hitung loss untuk pasangan negatif (target = -1)\n",
        "            negative_loss = loss_function(query_emb, neg_emb, torch.tensor([-1] * len(queries)).to(device))\n",
        "\n",
        "            loss = positive_loss + negative_loss\n",
        "\n",
        "            # --- Perbaiki model ---\n",
        "            loss.backward()  # Backpropagation: hitung bagaimana cara memperbaiki kesalahan\n",
        "            optimizer.step() # Terapkan perbaikan (update bobot) pada model\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Rata-rata Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    print(\"‚úÖ Proses training selesai.\")\n",
        "\n",
        "    # Simpan state dictionary dari model yang sudah dilatih\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    print(f\"üíæ Model yang telah dilatih disimpan di: {MODEL_SAVE_PATH}\")\n",
        "else:\n",
        "    print(\"üõë Training dilewati karena dataset tidak dimuat.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7Eg5inz5NEO",
        "outputId": "efac8316-ecbc-46b8-9497-66f518b0d0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Berhasil memuat 37 passage untuk pengujian.\n",
            "üìö Membuat embedding untuk semua materi...\n",
            "\n",
            "==================================================\n",
            "HASIL PERBANDINGAN MODEL\n",
            "==================================================\n",
            "\n",
            "\n",
            "‚ùì PERTANYAAN: 'apa kelemahan dari algoritma penjadwalan FCFS?'\n",
            "----------------------------------------\n",
            "--- 1. Hasil Model Dasar (Belum Belajar) ---\n",
            "Skor Relevansi: 0.5286\n",
            "Teks Ditemukan:\n",
            "- **Konsep:** Proses yang meminta CPU pertama kali akan dilayani pertama kali. [53, 54] Implementasi paling sederhana menggunakan antrian FIFO (First-In, First-Out). Ketika sebuah proses masuk ke ready queue, PCB-nya ditautkan ke akhir antrian. Ketika CPU bebas, ia dialokasikan ke proses di awal antrian.\n",
            "- **Sifat:** Non-preemptive. Sekali CPU diberikan ke suatu proses, proses tersebut akan menjalankannya hingga selesai atau melakukan permintaan I/O.\n",
            "- **Kelemahan:** Average waiting time (AWT) seringkali cukup panjang. Efek konvoi (convoy effect) dapat terjadi jika proses dengan burst time panjang datang lebih dulu dan membuat proses-proses pendek di belakangnya menunggu lama. Tidak cocok untuk sistem time-sharing.\n",
            "- **Contoh Perhitungan FCFS:** [54]\n",
            "  Misalkan proses datang dalam urutan P1, P2, P3 pada waktu 0 dengan burst time:\n",
            "  P1: 24 ms\n",
            "  P2: 3 ms\n",
            "  P3: 3 ms\n",
            "  Gantt Chart:\n",
            "  | P1 (0-24) | P2 (24-27) | P3 (27-30) |\n",
            "  Waiting time: P1 = 0; P2 = 24; P3 = 27\n",
            "  Average Waiting Time (AW\n",
            "\n",
            "--- 2. Hasil Model Kustom (Sudah Belajar) ---\n",
            "Skor Relevansi: 0.8811\n",
            "Teks Ditemukan:\n",
            "Berikut adalah beberapa algoritma penjadwalan yang umum:\n",
            "- First-Come, First-Served (FCFS)\n",
            "- Shortest-Job-First (SJF)\n",
            "- Priority Scheduling\n",
            "- Round-Robin (RR)\n",
            "\n",
            "\n",
            "‚ùì PERTANYAAN: 'apa yang dimaksud dengan context switch?'\n",
            "----------------------------------------\n",
            "--- 1. Hasil Model Dasar (Belum Belajar) ---\n",
            "Skor Relevansi: 0.5472\n",
            "Teks Ditemukan:\n",
            "Ketika CPU beralih dari satu proses ke proses lain, OS harus menyimpan status proses lama (dari PCB-nya) dan memuat status proses baru yang disimpan (ke PCB-nya). Operasi ini dikenal sebagai context switch.\n",
            "\n",
            "--- 2. Hasil Model Kustom (Sudah Belajar) ---\n",
            "Skor Relevansi: 0.9119\n",
            "Teks Ditemukan:\n",
            "Ketika CPU beralih dari satu proses ke proses lain, OS harus menyimpan status proses lama (dari PCB-nya) dan memuat status proses baru yang disimpan (ke PCB-nya). Operasi ini dikenal sebagai context switch.\n",
            "\n",
            "\n",
            "‚ùì PERTANYAAN: 'apa itu multiprogramming'\n",
            "----------------------------------------\n",
            "--- 1. Hasil Model Dasar (Belum Belajar) ---\n",
            "Skor Relevansi: 0.4425\n",
            "Teks Ditemukan:\n",
            "- **Operasi Program Tunggal (Mono-programming):** [12]\n",
            "  Hanya satu program yang dapat berjalan pada satu waktu. CPU sering idle menunggu I/O selesai.\n",
            "- **Pemrosesan Batch (Batch Processing):** [12]\n",
            "  Job-job dengan kebutuhan serupa dikumpulkan dan dijalankan secara berurutan tanpa intervensi pengguna.\n",
            "- **Multi-programming / Multi-tasking:** [12]\n",
            "  Beberapa program berada di memori pada saat yang sama. CPU beralih dari satu program ke program lain, memberikan ilusi bahwa semua program berjalan bersamaan. Meningkatkan utilisasi CPU.\n",
            "- **Multi-access (Time-sharing):** [13]\n",
            "  Variasi dari multiprogramming di mana banyak pengguna dapat berinteraksi dengan programnya masing-masing secara bersamaan melalui terminal. Setiap pengguna mendapatkan irisan waktu CPU (time slice).\n",
            "\n",
            "--- 2. Hasil Model Kustom (Sudah Belajar) ---\n",
            "Skor Relevansi: 0.6043\n",
            "Teks Ditemukan:\n",
            "- **Operasi Program Tunggal (Mono-programming):** [12]\n",
            "  Hanya satu program yang dapat berjalan pada satu waktu. CPU sering idle menunggu I/O selesai.\n",
            "- **Pemrosesan Batch (Batch Processing):** [12]\n",
            "  Job-job dengan kebutuhan serupa dikumpulkan dan dijalankan secara berurutan tanpa intervensi pengguna.\n",
            "- **Multi-programming / Multi-tasking:** [12]\n",
            "  Beberapa program berada di memori pada saat yang sama. CPU beralih dari satu program ke program lain, memberikan ilusi bahwa semua program berjalan bersamaan. Meningkatkan utilisasi CPU.\n",
            "- **Multi-access (Time-sharing):** [13]\n",
            "  Variasi dari multiprogramming di mana banyak pengguna dapat berinteraksi dengan programnya masing-masing secara bersamaan melalui terminal. Setiap pengguna mendapatkan irisan waktu CPU (time slice).\n"
          ]
        }
      ],
      "source": [
        "#@title 5. Uji Coba: Membandingkan Model Sebelum dan Sesudah \"Belajar\"\n",
        "# ------------------------------------------------------------------\n",
        "# Menguji kemampuan model dasar vs. model yang kita latih untuk\n",
        "# menunjukkan dampak nyata dari proses fine-tuning.\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# Muat materi kuliah untuk pengujian\n",
        "try:\n",
        "    # ANDA PERLU MENGUNGGAH FILE INI KE SESI COLAB ANDA\n",
        "    # Nama file bisa: 'processed_chunks_metadata_base.json', 'processed_chunks_metadata_kecerdasan_buatan.json', dll.\n",
        "    with open('/content/processed_chunks_metadata_base.json', 'r', encoding='utf-8') as f:\n",
        "        all_chunks = json.load(f)\n",
        "    all_passages_for_test = [chunk['chunk_text'] for chunk in all_chunks]\n",
        "    print(f\"‚úÖ Berhasil memuat {len(all_passages_for_test)} passage untuk pengujian.\")\n",
        "except Exception as e:\n",
        "    all_passages_for_test = []\n",
        "    print(f\"üõë Gagal memuat passage untuk pengujian. Pastikan file materi sudah diunggah ke /content/: {e}\")\n",
        "\n",
        "\n",
        "if all_passages_for_test and os.path.exists(MODEL_SAVE_PATH):\n",
        "    # 1. Inisialisasi kedua model\n",
        "    base_model = SentenceTransformer(BASE_MODEL_NAME).to(device)\n",
        "\n",
        "    # Inisialisasi ulang arsitektur dan muat bobot yang telah kita latih\n",
        "    finetuned_model = SentenceTransformer(BASE_MODEL_NAME)\n",
        "    finetuned_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "    finetuned_model.to(device)\n",
        "\n",
        "    base_model.eval()\n",
        "    finetuned_model.eval()\n",
        "\n",
        "    # 2. Buat embedding untuk semua materi menggunakan KEDUA model\n",
        "    print(\"üìö Membuat embedding untuk semua materi...\")\n",
        "    with torch.no_grad():\n",
        "        corpus_embeddings_base = base_model.encode(all_passages_for_test, convert_to_tensor=True, device=device)\n",
        "        corpus_embeddings_finetuned = finetuned_model.encode(all_passages_for_test, convert_to_tensor=True, device=device)\n",
        "\n",
        "    # 3. Lakukan pengujian dengan query yang lebih strategis\n",
        "    test_queries = [\n",
        "        \"apa kelemahan dari algoritma penjadwalan FCFS?\",\n",
        "        \"apa yang dimaksud dengan context switch?\",\n",
        "        \"apa itu multiprogramming\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\nHASIL PERBANDINGAN MODEL\\n\" + \"=\"*50)\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\n\\n‚ùì PERTANYAAN: '{query}'\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # --- PENGUJIAN MODEL DASAR (SEBELUM BELAJAR) ---\n",
        "        with torch.no_grad():\n",
        "            query_embedding_base = base_model.encode(query, convert_to_tensor=True, device=device)\n",
        "        cos_scores_base = util.cos_sim(query_embedding_base, corpus_embeddings_base)[0]\n",
        "        top_result_base = torch.topk(cos_scores_base, k=1)\n",
        "\n",
        "        print(\"--- 1. Hasil Model Dasar (Belum Belajar) ---\")\n",
        "        for score, idx in zip(top_result_base[0], top_result_base[1]):\n",
        "            print(f\"Skor Relevansi: {score.item():.4f}\")\n",
        "            print(f\"Teks Ditemukan:\\n{all_passages_for_test[idx]}\")\n",
        "\n",
        "        # --- PENGUJIAN MODEL KUSTOM (SETELAH BELAJAR) ---\n",
        "        with torch.no_grad():\n",
        "            query_embedding_finetuned = finetuned_model.encode(query, convert_to_tensor=True, device=device)\n",
        "        cos_scores_finetuned = util.cos_sim(query_embedding_finetuned, corpus_embeddings_finetuned)[0]\n",
        "        top_result_finetuned = torch.topk(cos_scores_finetuned, k=1)\n",
        "\n",
        "        print(\"\\n--- 2. Hasil Model Kustom (Sudah Belajar) ---\")\n",
        "        for score, idx in zip(top_result_finetuned[0], top_result_finetuned[1]):\n",
        "            print(f\"Skor Relevansi: {score.item():.4f}\")\n",
        "            print(f\"Teks Ditemukan:\\n{all_passages_for_test[idx]}\")\n",
        "\n",
        "else:\n",
        "    print(\"üõë Pengujian dilewati. Pastikan model telah dilatih dan data materi tersedia.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
