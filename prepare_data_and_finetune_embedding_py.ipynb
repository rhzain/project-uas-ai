{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBSUcjCAEPhy",
        "outputId": "035bf6a1-2ae7-49ab-9f11-80ba7bb8a6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss_cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss_cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss_cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
        "from torch.utils.data import DataLoader\n",
        "import faiss\n",
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import glob\n",
        "import google.generativeai as genai\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import random"
      ],
      "metadata": {
        "id": "A-hgbZr0EVaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/dataset.zip'\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    print(f\"Zip file '{zip_file_path}' has been extracted successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file not found at '{zip_file_path}'\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path}' is not a valid zip file\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during extraction: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScqrvT3LFhys",
        "outputId": "4b804035-d6a1-4096-e9df-72786e8dd70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file '/content/dataset.zip' has been extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Konfigurasi ---\n",
        "BASE_DIR = \"dataset/SistemOperasi\"  # Direktori utama mata kuliah Anda\n",
        "OUTLINE_FILE = os.path.join(BASE_DIR, \"outline_operating_systems.txt\")\n",
        "\n",
        "# --- Path untuk Artefak Model Dasar (Baseline) ---\n",
        "BASE_EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
        "OUTPUT_JSON_CHUNKS_BASE = os.path.join(BASE_DIR, \"processed_chunks_metadata_base.json\")\n",
        "OUTPUT_FAISS_INDEX_BASE = os.path.join(BASE_DIR, \"vector_store_base.index\")\n",
        "\n",
        "# --- Path untuk Artefak Model Fine-Tuned ---\n",
        "# Ini akan menjadi output utama yang digunakan aplikasi jika fine-tuning berhasil\n",
        "FINETUNED_EMBEDDING_MODEL_SAVE_PATH = os.path.join(BASE_DIR, \"finetuned_embedding_model_sistem_operasi\")\n",
        "FINETUNED_MODEL_ZIP_PATH = os.path.join(BASE_DIR, \"finetuned_embedding_model_sistem_operasi.zip\")\n",
        "OUTPUT_JSON_CHUNKS_FINETUNED = os.path.join(BASE_DIR, \"processed_chunks_metadata_finetuned.json\")\n",
        "OUTPUT_FAISS_INDEX_FINETUNED = os.path.join(BASE_DIR, \"vector_store_finetuned.index\")\n",
        "\n",
        "\n",
        "# --- File Dataset ---\n",
        "EMBEDDING_FINETUNING_DATASET_FILE = os.path.join(BASE_DIR, \"embedding_finetuning_examples.jsonl\")\n",
        "EMBEDDING_EVALUATION_SET_FILE = os.path.join(BASE_DIR, \"embedding_evaluation_set.jsonl\")\n",
        "\n",
        "\n",
        "# --- Parameter ---\n",
        "MAX_CHUNK_SIZE_CHARS = 1000\n",
        "CHUNK_OVERLAP_CHARS = 150\n",
        "HEADING_SPLIT_PATTERN = r\"(^#{1,6}\\s+.*$)\"\n",
        "FINETUNE_EPOCHS = 3 # Sesuaikan berdasarkan dataset Anda\n",
        "FINETUNE_BATCH_SIZE = 16\n",
        "EVALUATION_TOP_K = 5 # Untuk Recall@K dan MRR@K\n",
        "FINETUNE_BATCH_SIZE = 16"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "fn3CY5OsDG0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fungsi Helper (Parsing, Chunking - sebagian besar sama) ---\n",
        "def parse_outline(outline_filepath):\n",
        "    pertemuan_list = []\n",
        "    try:\n",
        "        with open(outline_filepath, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        if not content.strip().startswith(\"MATAKULIAH:\"):\n",
        "            print(f\"Peringatan: Format file outline '{outline_filepath}' mungkin tidak sesuai.\")\n",
        "        pertemuan_blocks = re.split(r'\\nPERTEMUAN:', '\\n' + content.split('PERTEMUAN:', 1)[-1] if 'PERTEMUAN:' in content else '')\n",
        "        for block in pertemuan_blocks:\n",
        "            if not block.strip(): continue\n",
        "            current_pertemuan = {}\n",
        "            lines = block.strip().splitlines()\n",
        "            if lines:\n",
        "                pertemuan_id_match = re.match(r'^\\s*(\\d+)', lines[0])\n",
        "                if pertemuan_id_match: current_pertemuan['id'] = int(pertemuan_id_match.group(1))\n",
        "                else: continue # Skip jika tidak ada ID\n",
        "                for line_idx, line_content in enumerate(lines): # Ganti nama variabel 'line'\n",
        "                    if \":\" in line_content:\n",
        "                        key, value = line_content.split(\":\", 1)\n",
        "                        key_clean = key.strip().lower().replace(\" \", \"_\")\n",
        "                        value_clean = value.strip()\n",
        "                        current_pertemuan[key_clean] = value_clean\n",
        "            if 'id' in current_pertemuan and 'judul' in current_pertemuan and current_pertemuan.get('file_materi'):\n",
        "                pertemuan_list.append(current_pertemuan)\n",
        "            elif 'id' in current_pertemuan:\n",
        "                 print(f\"Info: Pertemuan {current_pertemuan.get('id','N/A')} ({current_pertemuan.get('judul','Tanpa Judul')}) dilewati (mungkin kurang file_materi atau judul).\")\n",
        "    except FileNotFoundError: print(f\"Error: File outline '{outline_filepath}' tidak ditemukan.\")\n",
        "    except Exception as e: print(f\"Error saat mem-parsing file outline: {e}\")\n",
        "    print(f\"Berhasil mem-parsing {len(pertemuan_list)} pertemuan dengan file materi dari outline.\")\n",
        "    return pertemuan_list\n",
        "\n",
        "def read_material_text(material_filepath):\n",
        "    try:\n",
        "        with open(material_filepath, 'r', encoding='utf-8') as f: return f.read()\n",
        "    except FileNotFoundError: print(f\"Error: File materi '{material_filepath}' tidak ditemukan.\"); return \"\"\n",
        "    except Exception as e: print(f\"Error saat membaca file materi '{material_filepath}': {e}\"); return \"\"\n",
        "\n",
        "def _split_text_block_sliding_window(text_block, pertemuan_id, pertemuan_judul, heading, max_size, overlap):\n",
        "    final_chunks = []\n",
        "    text_block_stripped = text_block.strip()\n",
        "    if not text_block_stripped: return []\n",
        "    if len(text_block_stripped) <= max_size:\n",
        "        final_chunks.append({\"pertemuan_id\": pertemuan_id, \"pertemuan_judul\": pertemuan_judul, \"original_heading\": heading, \"chunk_text\": text_block_stripped, \"chunk_id\": f\"p{pertemuan_id}_h{hash(heading)}_{len(final_chunks)}\"})\n",
        "    else:\n",
        "        start_index = 0; doc_len = len(text_block_stripped)\n",
        "        while start_index < doc_len:\n",
        "            end_index = start_index + max_size\n",
        "            current_slice = text_block_stripped[start_index:min(end_index, doc_len)]\n",
        "            if current_slice.strip():\n",
        "                final_chunks.append({\"pertemuan_id\": pertemuan_id, \"pertemuan_judul\": pertemuan_judul, \"original_heading\": heading, \"chunk_text\": current_slice.strip(), \"chunk_id\": f\"p{pertemuan_id}_h{hash(heading)}_{len(final_chunks)}\"})\n",
        "            if min(end_index, doc_len) >= doc_len: break\n",
        "            start_index += (max_size - overlap)\n",
        "            if start_index >= doc_len: break\n",
        "    return final_chunks\n",
        "\n",
        "def chunk_material_heading_aware(text_content, pertemuan_id, pertemuan_judul):\n",
        "    processed_chunks = []; current_chunk_idx = 0\n",
        "    if not text_content or not text_content.strip(): return []\n",
        "    parts = re.split(HEADING_SPLIT_PATTERN, text_content, flags=re.MULTILINE)\n",
        "    current_heading = \"Umum\"; accumulated_text_for_section = \"\"\n",
        "    for i, part in enumerate(parts):\n",
        "        part_stripped = part.strip()\n",
        "        if not part_stripped: continue\n",
        "        is_current_part_a_heading = re.match(HEADING_SPLIT_PATTERN, part_stripped, flags=re.MULTILINE)\n",
        "        if is_current_part_a_heading:\n",
        "            if accumulated_text_for_section.strip():\n",
        "                sub_chunks = _split_text_block_sliding_window(accumulated_text_for_section, pertemuan_id, pertemuan_judul, current_heading, MAX_CHUNK_SIZE_CHARS, CHUNK_OVERLAP_CHARS)\n",
        "                for sc_idx, sc in enumerate(sub_chunks): sc['chunk_id'] = f\"p{pertemuan_id}_s{i}_sc{sc_idx}\"; processed_chunks.append(sc) # ID chunk yang lebih unik\n",
        "            current_heading = part_stripped; accumulated_text_for_section = \"\"\n",
        "        else: accumulated_text_for_section += part_stripped + \"\\n\"\n",
        "    if accumulated_text_for_section.strip():\n",
        "        sub_chunks = _split_text_block_sliding_window(accumulated_text_for_section, pertemuan_id, pertemuan_judul, current_heading, MAX_CHUNK_SIZE_CHARS, CHUNK_OVERLAP_CHARS)\n",
        "        for sc_idx, sc in enumerate(sub_chunks): sc['chunk_id'] = f\"p{pertemuan_id}_s_last_sc{sc_idx}\"; processed_chunks.append(sc)\n",
        "    return processed_chunks\n",
        "\n",
        "def get_text_embeddings_from_model(list_of_chunk_texts, embedding_model_instance):\n",
        "    if not list_of_chunk_texts: print(\"Tidak ada teks untuk di-embed.\"); return np.array([])\n",
        "    try:\n",
        "        print(f\"Memulai proses embedding untuk {len(list_of_chunk_texts)} chunk teks...\")\n",
        "        embeddings = embedding_model_instance.encode(list_of_chunk_texts, show_progress_bar=True, batch_size=128)\n",
        "        print(f\"Proses embedding selesai. Dihasilkan {embeddings.shape[0]} embeddings dengan dimensi {embeddings.shape[1]}.\")\n",
        "        return embeddings\n",
        "    except Exception as e: print(f\"Error saat membuat embeddings: {e}\"); return np.array([])\n",
        "\n",
        "def create_and_save_faiss_index(embeddings_np_array, index_output_path):\n",
        "    if embeddings_np_array.size == 0 or embeddings_np_array.ndim != 2: print(\"Array embedding kosong. FAISS index tidak dibuat.\"); return False\n",
        "    dimension = embeddings_np_array.shape[1]\n",
        "    try:\n",
        "        print(f\"Membuat FAISS index dengan dimensi {dimension}...\")\n",
        "        index = faiss.IndexFlatL2(dimension)\n",
        "        index.add(embeddings_np_array.astype('float32'))\n",
        "        faiss.write_index(index, index_output_path)\n",
        "        print(f\"FAISS index dengan {index.ntotal} vektor disimpan ke: {index_output_path}\")\n",
        "        return True\n",
        "    except Exception as e: print(f\"Error saat membuat/menyimpan FAISS index: {e}\"); return False\n",
        "\n",
        "def save_chunks_to_json(chunks_with_metadata, json_output_path):\n",
        "    try:\n",
        "        with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(chunks_with_metadata, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Semua chunk ({len(chunks_with_metadata)}) berhasil disimpan ke: {json_output_path}\")\n",
        "        return True\n",
        "    except Exception as e: print(f\"Error saat menyimpan chunks ke JSON: {e}\"); return False\n",
        "\n",
        "# --- Fungsi Fine-Tuning & Evaluasi Embedding ---\n",
        "def load_embedding_finetuning_dataset(filepath):\n",
        "    train_examples = []\n",
        "    if not os.path.exists(filepath): print(f\"PERINGATAN: File dataset fine-tuning '{filepath}' tidak ditemukan.\"); return []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line_content in enumerate(f):\n",
        "            try:\n",
        "                data = json.loads(line_content)\n",
        "                if \"query\" in data and \"positive_passage\" in data:\n",
        "                    train_examples.append(InputExample(texts=[data[\"query\"], data[\"positive_passage\"]]))\n",
        "                else: print(f\"Peringatan: Baris data tidak valid di {filepath} (baris {line_num+1})\")\n",
        "            except json.JSONDecodeError: print(f\"Peringatan: Gagal parsing JSON di {filepath} (baris {line_num+1})\")\n",
        "    print(f\"Berhasil memuat {len(train_examples)} contoh dari {filepath} untuk fine-tuning embedding.\")\n",
        "    return train_examples\n",
        "\n",
        "def finetune_embedding_model(base_model_name, train_examples, output_path, epochs, batch_size):\n",
        "    if not train_examples:\n",
        "        print(\"Tidak ada data training. Fine-tuning embedding dilewati.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Memulai fine-tuning model embedding '{base_model_name}'...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "    model = SentenceTransformer(base_model_name)\n",
        "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
        "    train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "              epochs=epochs,\n",
        "              warmup_steps=int(len(train_dataloader) * epochs * 0.1),\n",
        "              output_path=output_path,\n",
        "              show_progress_bar=True,\n",
        "              save_best_model=False)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Fine-tuning selesai dalam {end_time - start_time:.2f} detik. Model disimpan di: {output_path}\")\n",
        "\n",
        "    try:\n",
        "        return SentenceTransformer(output_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Peringatan: Gagal memuat model dari '{output_path}' setelah fine-tuning: {e}\")\n",
        "        print(\"Mengembalikan None. Periksa apakah direktori model berisi semua file yang diperlukan.\")\n",
        "        return None\n",
        "\n",
        "def load_embedding_evaluation_dataset(filepath):\n",
        "    eval_data = []\n",
        "    if not os.path.exists(filepath): print(f\"PERINGATAN: File dataset evaluasi '{filepath}' tidak ditemukan.\"); return []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line_content in enumerate(f):\n",
        "            try:\n",
        "                data = json.loads(line_content)\n",
        "                if \"query_id\" in data and \"query_text\" in data and \"relevant_passage_text\" in data: # Ganti nama field\n",
        "                    eval_data.append(data)\n",
        "                else: print(f\"Peringatan: Baris data evaluasi tidak valid di {filepath} (baris {line_num+1})\")\n",
        "            except json.JSONDecodeError: print(f\"Peringatan: Gagal parsing JSON di data evaluasi {filepath} (baris {line_num+1})\")\n",
        "    print(f\"Berhasil memuat {len(eval_data)} contoh dari {filepath} untuk evaluasi embedding.\")\n",
        "    return eval_data\n",
        "\n",
        "def evaluate_retrieval_performance(embedding_model_instance, faiss_index_instance, text_chunks_list, eval_dataset, top_k):\n",
        "    if not eval_dataset or embedding_model_instance is None or faiss_index_instance is None or not text_chunks_list:\n",
        "        print(\"Input tidak lengkap untuk evaluasi retrieval. Dilewati.\")\n",
        "        return {\"avg_recall_at_k\": 0, \"avg_mrr_at_k\": 0, \"queries_evaluated\": 0}\n",
        "\n",
        "    total_recall = 0; total_mrr = 0; queries_evaluated = 0\n",
        "    for item in eval_dataset:\n",
        "        query_text = item[\"query_text\"]\n",
        "        relevant_passage_ground_truth = item[\"relevant_passage_text\"].strip().lower()\n",
        "\n",
        "        query_embedding = embedding_model_instance.encode([query_text])[0]\n",
        "        query_np_array = np.array([query_embedding]).astype('float32')\n",
        "\n",
        "        if faiss_index_instance.d != query_np_array.shape[1]:\n",
        "            print(f\"  Peringatan Evaluasi: Dimensi embedding query ({query_np_array.shape[1]}) tidak cocok dengan FAISS ({faiss_index_instance.d}).\")\n",
        "            continue\n",
        "\n",
        "        distances, global_indices = faiss_index_instance.search(query_np_array, min(top_k, faiss_index_instance.ntotal))\n",
        "\n",
        "        retrieved_passages = []\n",
        "        for i in global_indices[0]:\n",
        "            if i != -1 and 0 <= i < len(text_chunks_list):\n",
        "                retrieved_passages.append(text_chunks_list[i][\"chunk_text\"].strip().lower())\n",
        "\n",
        "        found_in_top_k = False\n",
        "        rank = 0\n",
        "        for idx, passage in enumerate(retrieved_passages):\n",
        "            if relevant_passage_ground_truth in passage: # Menggunakan 'in' untuk pencocokan substring\n",
        "                if not found_in_top_k: # Hanya hitung rank pertama kali ditemukan\n",
        "                    rank = idx + 1\n",
        "                    total_mrr += 1.0 / rank\n",
        "                found_in_top_k = True\n",
        "                break # Hentikan pencarian jika sudah ditemukan\n",
        "\n",
        "        if found_in_top_k: total_recall += 1\n",
        "        queries_evaluated += 1\n",
        "\n",
        "    avg_recall = total_recall / queries_evaluated if queries_evaluated > 0 else 0\n",
        "    avg_mrr = total_mrr / queries_evaluated if queries_evaluated > 0 else 0\n",
        "    return {\"avg_recall_at_k\": avg_recall, \"avg_mrr_at_k\": avg_mrr, \"queries_evaluated\": queries_evaluated}\n",
        "\n",
        "def zip_model_directory(directory_path, zip_output_path):\n",
        "    if not os.path.isdir(directory_path):\n",
        "        print(f\"Error: Direktori model '{directory_path}' tidak ditemukan. Tidak dapat membuat zip.\")\n",
        "        return False\n",
        "    try:\n",
        "        # Hapus file zip lama jika ada\n",
        "        if os.path.exists(zip_output_path):\n",
        "            os.remove(zip_output_path)\n",
        "            print(f\"File zip lama '{zip_output_path}' dihapus.\")\n",
        "\n",
        "        shutil.make_archive(zip_output_path.replace('.zip',''), 'zip', directory_path) # make_archive menambahkan .zip otomatis\n",
        "        print(f\"Model berhasil di-zip ke: {zip_output_path}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat membuat arsip zip: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "nLe9he5BEbjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_queries_from_passage_with_llm(passage_text, llm_model_instance, num_queries=1, max_retries=2, delay_between_retries=5):\n",
        "    \"\"\"\n",
        "    Menghasilkan pertanyaan dari sebuah passage menggunakan LLM (Gemini).\n",
        "    \"\"\"\n",
        "    if not llm_model_instance:\n",
        "        print(\"  LLM model instance tidak tersedia untuk question generation.\")\n",
        "        return []\n",
        "\n",
        "    prompt = f\"\"\"Anda adalah seorang ahli dalam membuat pertanyaan berdasarkan teks yang diberikan.\n",
        "Berdasarkan teks berikut, buatlah {num_queries} pertanyaan yang spesifik, jelas, dan bisa dijawab secara langsung oleh teks tersebut.\n",
        "Setiap pertanyaan harus berbeda. Kembalikan hanya daftar pertanyaan, masing-masing dalam baris baru, tanpa nomor atau bullet point.\n",
        "\n",
        "Teks:\n",
        "\\\"\\\"\\\"\n",
        "{passage_text[:1500]}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Pertanyaan:\n",
        "\"\"\"\n",
        "    # Batasi panjang passage untuk efisiensi prompt\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = llm_model_instance.generate_content(prompt)\n",
        "            # Cek apakah ada 'parts' dan ambil teksnya, atau langsung dari 'text'\n",
        "            if hasattr(response, 'parts') and response.parts:\n",
        "                generated_text = \"\".join(part.text for part in response.parts)\n",
        "            elif hasattr(response, 'text') and response.text:\n",
        "                generated_text = response.text\n",
        "            else: # Jika tidak ada parts atau text, coba cek prompt_feedback\n",
        "                if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:\n",
        "                    print(f\"  Peringatan LLM QGen: Respons diblokir. Alasan: {response.prompt_feedback.block_reason_message}\")\n",
        "                else:\n",
        "                    print(f\"  Peringatan LLM QGen: Respons tidak memiliki format teks yang diharapkan. Respons: {response}\")\n",
        "                generated_text = \"\"\n",
        "\n",
        "            questions = [q.strip() for q in generated_text.splitlines() if q.strip()]\n",
        "\n",
        "            if questions: # Jika berhasil mendapatkan pertanyaan\n",
        "                # Pastikan tidak ada pertanyaan kosong setelah strip\n",
        "                questions = [q for q in questions if q]\n",
        "                if questions:\n",
        "                     print(f\"  LLM berhasil generate {len(questions)} pertanyaan untuk passage.\")\n",
        "                     return questions[:num_queries] # Ambil sejumlah num_queries\n",
        "\n",
        "            print(f\"  LLM tidak menghasilkan pertanyaan yang valid (attempt {attempt + 1}/{max_retries}). Respons mentah: '{generated_text}'\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error saat memanggil LLM untuk question generation (attempt {attempt + 1}/{max_retries}): {e}\")\n",
        "\n",
        "        if attempt < max_retries - 1:\n",
        "            print(f\"  Menunggu {delay_between_retries} detik sebelum mencoba lagi...\")\n",
        "            time.sleep(delay_between_retries)\n",
        "\n",
        "    return []\n",
        "\n",
        "\n",
        "def create_embedding_finetune_dataset_with_llm(\n",
        "    all_processed_chunks,\n",
        "    llm_model_instance_for_qgen,\n",
        "    num_queries_per_chunk=1,\n",
        "    output_filepath=None,\n",
        "    max_chunks_to_process=None # Opsional: batasi jumlah chunk untuk diolah (untuk testing)\n",
        "):\n",
        "    \"\"\"\n",
        "    Membuat dataset fine-tuning (query, positive_passage) menggunakan LLM untuk membuat query.\n",
        "    Menyimpan hasilnya ke output_filepath jika diberikan.\n",
        "    \"\"\"\n",
        "    train_examples_data = []\n",
        "\n",
        "    chunks_to_process = all_processed_chunks\n",
        "    if max_chunks_to_process is not None:\n",
        "        chunks_to_process = all_processed_chunks[:max_chunks_to_process]\n",
        "        print(f\"Memproses {max_chunks_to_process} chunk pertama untuk pembuatan dataset fine-tuning dengan LLM.\")\n",
        "\n",
        "    processed_count = 0\n",
        "    for i, chunk_data in enumerate(chunks_to_process):\n",
        "        print(f\"Memproses chunk {i+1}/{len(chunks_to_process)} untuk Q-Gen...\")\n",
        "        passage = chunk_data[\"chunk_text\"]\n",
        "        generated_queries = generate_queries_from_passage_with_llm(\n",
        "            passage, llm_model_instance_for_qgen, num_queries_per_chunk\n",
        "        )\n",
        "        for query in generated_queries:\n",
        "            train_examples_data.append({\"query\": query, \"positive_passage\": passage})\n",
        "\n",
        "        processed_count +=1\n",
        "        # Opsional: tambahkan delay kecil untuk menghindari rate limit API\n",
        "        if processed_count % 10 == 0: # Setiap 10 chunk\n",
        "             time.sleep(1)\n",
        "\n",
        "\n",
        "    if output_filepath and train_examples_data:\n",
        "        try:\n",
        "            with open(output_filepath, 'w', encoding='utf-8') as f:\n",
        "                for example in train_examples_data:\n",
        "                    f.write(json.dumps(example) + '\\n')\n",
        "            print(f\"Dataset fine-tuning embedding ({len(train_examples_data)} contoh) berhasil dibuat dan disimpan di: {output_filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saat menyimpan dataset fine-tuning ke {output_filepath}: {e}\")\n",
        "    elif not train_examples_data:\n",
        "        print(\"Tidak ada contoh fine-tuning yang berhasil dibuat dengan LLM.\")\n",
        "\n",
        "    # Mengembalikan format InputExample jika ingin langsung digunakan untuk training\n",
        "    # atau biarkan skrip utama yang memanggil `load_embedding_finetuning_dataset`\n",
        "    # Untuk konsistensi, kita simpan ke file dan biarkan `load_embedding_finetuning_dataset` yang memuatnya.\n",
        "    return train_examples_data # Mengembalikan list of dicts"
      ],
      "metadata": {
        "id": "yn82eMk-ROzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "print(\"Memulai Persiapan Data, Fine-Tuning, dan Evaluasi Embedding...\")\n",
        "\n",
        "# 1. Parse outline & Buat Chunks Materi (dilakukan sekali)\n",
        "print(f\"\\n--- Langkah 1: Memproses Materi Kuliah ---\")\n",
        "daftar_pertemuan = parse_outline(OUTLINE_FILE)\n",
        "all_processed_chunks_with_metadata = []\n",
        "\n",
        "llm_for_qgen = None\n",
        "GEMINI_API_KEY_FOR_PREP = userdata.get('GEMINI')\n",
        "\n",
        "if GEMINI_API_KEY_FOR_PREP:\n",
        "    try:\n",
        "        genai.configure(api_key=GEMINI_API_KEY_FOR_PREP)\n",
        "        print(\"Gemini API berhasil dikonfigurasi (atau dikonfigurasi ulang) dengan API Key dari userdata.\")\n",
        "\n",
        "        llm_for_qgen = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        print(\"Model LLM ('gemini-1.5-flash-latest') untuk Question Generation berhasil dimuat.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Peringatan: Terjadi kesalahan saat mengkonfigurasi atau memuat model Gemini untuk QGen: {e}\")\n",
        "        llm_for_qgen = None\n",
        "else:\n",
        "    print(\"PERINGATAN: Secret 'GEMINI' (API Key) tidak ditemukan di Colab userdata. Question Generation dengan LLM akan dilewati.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKDbwWS2zHqW",
        "outputId": "ed593e7f-8cf6-44fc-b90e-ec808994ef0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai Persiapan Data, Fine-Tuning, dan Evaluasi Embedding...\n",
            "\n",
            "--- Langkah 1: Memproses Materi Kuliah ---\n",
            "Berhasil mem-parsing 4 pertemuan dengan file materi dari outline.\n",
            "Gemini API berhasil dikonfigurasi (atau dikonfigurasi ulang) dengan API Key dari userdata.\n",
            "Model LLM ('gemini-1.5-flash-latest') untuk Question Generation berhasil dimuat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if daftar_pertemuan:\n",
        "    for pertemuan_info in daftar_pertemuan:\n",
        "        file_materi_abs_path = os.path.join(BASE_DIR, pertemuan_info.get('file_materi',''))\n",
        "        materi_text = read_material_text(file_materi_abs_path)\n",
        "        if materi_text:\n",
        "            chunks_for_this_pertemuan = chunk_material_heading_aware(materi_text, pertemuan_info.get('id'), pertemuan_info.get('judul'))\n",
        "            all_processed_chunks_with_metadata.extend(chunks_for_this_pertemuan)\n",
        "    print(f\"Total chunk materi yang diproses: {len(all_processed_chunks_with_metadata)}\")\n",
        "else:\n",
        "    print(\"Gagal mem-parsing outline atau tidak ada materi. Proses dihentikan.\")\n",
        "    exit()\n",
        "\n",
        "if not all_processed_chunks_with_metadata:\n",
        "    print(\"Tidak ada chunk materi yang berhasil dibuat. Proses dihentikan.\")\n",
        "    exit()\n",
        "\n",
        "list_of_chunk_texts_for_embedding = [chunk['chunk_text'] for chunk in all_processed_chunks_with_metadata]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_dZdIpvzNrC",
        "outputId": "87635c96-6086-4bd5-a255-180d3b59caa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunk materi yang diproses: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(EMBEDDING_FINETUNING_DATASET_FILE) and llm_for_qgen and all_processed_chunks_with_metadata:\n",
        "    print(f\"\\n--- Langkah Opsional: Membuat Dataset Fine-tuning Embedding dengan LLM ---\")\n",
        "    print(f\"File {EMBEDDING_FINETUNING_DATASET_FILE} tidak ditemukan. Mencoba membuat secara otomatis...\")\n",
        "    create_embedding_finetune_dataset_with_llm(\n",
        "        all_processed_chunks_with_metadata,\n",
        "        llm_for_qgen,\n",
        "        num_queries_per_chunk=1, # Buat 1 pertanyaan per chunk\n",
        "        output_filepath=EMBEDDING_FINETUNING_DATASET_FILE,\n",
        "        max_chunks_to_process=5 # Hapus atau naikkan angka ini untuk memproses semua chunk\n",
        "                                  # Gunakan angka kecil untuk testing agar tidak lama dan boros API call.\n",
        "    )\n",
        "elif not llm_for_qgen and not os.path.exists(EMBEDDING_FINETUNING_DATASET_FILE):\n",
        "    print(f\"PERINGATAN: LLM untuk Q-Gen tidak tersedia DAN file {EMBEDDING_FINETUNING_DATASET_FILE} tidak ada. Fine-tuning akan dilewati.\")"
      ],
      "metadata": {
        "id": "zPrTA1zAzLdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Muat dataset untuk fine-tuning dan evaluasi\n",
        "print(f\"\\n--- Langkah 2: Memuat Dataset Tambahan ---\")\n",
        "embedding_finetune_examples = load_embedding_finetuning_dataset(EMBEDDING_FINETUNING_DATASET_FILE)\n",
        "embedding_evaluation_examples = load_embedding_evaluation_dataset(EMBEDDING_EVALUATION_SET_FILE)\n",
        "metrics_base = None\n",
        "metrics_finetuned = None\n",
        "\n",
        "# --- BASELINE MODEL: Pembuatan Artefak & Evaluasi ---\n",
        "print(f\"\\n--- Langkah 3: Memproses dengan Model Embedding Dasar ({BASE_EMBEDDING_MODEL_NAME}) ---\")\n",
        "base_embedding_model_instance = SentenceTransformer(BASE_EMBEDDING_MODEL_NAME)\n",
        "base_document_embeddings = get_text_embeddings_from_model(list_of_chunk_texts_for_embedding, base_embedding_model_instance)\n",
        "\n",
        "base_faiss_created = False\n",
        "if base_document_embeddings.size > 0:\n",
        "    base_faiss_created = create_and_save_faiss_index(base_document_embeddings, OUTPUT_FAISS_INDEX_BASE)\n",
        "    save_chunks_to_json(all_processed_chunks_with_metadata, OUTPUT_JSON_CHUNKS_BASE) # Simpan chunks yang sesuai\n",
        "\n",
        "if base_faiss_created and embedding_evaluation_examples:\n",
        "    print(f\"\\n--- Langkah 3.1: Evaluasi Performa Retrieval Model Dasar ---\")\n",
        "    # Muat FAISS index yang baru dibuat untuk evaluasi\n",
        "    base_faiss_index_for_eval = faiss.read_index(OUTPUT_FAISS_INDEX_BASE)\n",
        "    metrics_base = evaluate_retrieval_performance(\n",
        "        base_embedding_model_instance, base_faiss_index_for_eval, all_processed_chunks_with_metadata,\n",
        "        embedding_evaluation_examples, EVALUATION_TOP_K\n",
        "    )\n",
        "    print(f\"Metrik Model Dasar: Recall@{EVALUATION_TOP_K}={metrics_base['avg_recall_at_k']:.4f}, MRR@{EVALUATION_TOP_K}={metrics_base['avg_mrr_at_k']:.4f} ({metrics_base['queries_evaluated']} queries)\")\n",
        "\n",
        "# --- FINE-TUNING EMBEDDING MODEL ---\n",
        "print(f\"\\n--- Langkah 4: Fine-Tuning Model Embedding ---\")\n",
        "finetuned_embedding_model_instance = None\n",
        "if embedding_finetune_examples:\n",
        "    finetuned_embedding_model_instance = finetune_embedding_model(\n",
        "        BASE_EMBEDDING_MODEL_NAME, embedding_finetune_examples,\n",
        "        FINETUNED_EMBEDDING_MODEL_SAVE_PATH, FINETUNE_EPOCHS, FINETUNE_BATCH_SIZE\n",
        "    )\n",
        "else:\n",
        "    print(\"Tidak ada data fine-tuning, menggunakan model dasar sebagai model akhir.\")\n",
        "\n",
        "# Tentukan model mana yang akan digunakan untuk artefak final (yang akan dipakai aplikasi)\n",
        "active_embedding_model_for_final_artifacts = finetuned_embedding_model_instance if finetuned_embedding_model_instance else base_embedding_model_instance\n",
        "active_model_name_for_log = FINETUNED_EMBEDDING_MODEL_SAVE_PATH if finetuned_embedding_model_instance else BASE_EMBEDDING_MODEL_NAME\n",
        "\n",
        "print(f\"\\n--- Langkah 5: Membuat Artefak RAG Final dengan Model '{active_model_name_for_log}' ---\")\n",
        "final_document_embeddings = get_text_embeddings_from_model(list_of_chunk_texts_for_embedding, active_embedding_model_for_final_artifacts)\n",
        "\n",
        "final_faiss_created = False\n",
        "if final_document_embeddings.size > 0:\n",
        "    final_faiss_created = create_and_save_faiss_index(final_document_embeddings, OUTPUT_FAISS_INDEX_FINETUNED)\n",
        "    save_chunks_to_json(all_processed_chunks_with_metadata, OUTPUT_JSON_CHUNKS_FINETUNED)\n",
        "\n",
        "if final_faiss_created and finetuned_embedding_model_instance and embedding_evaluation_examples:\n",
        "    print(f\"\\n--- Langkah 5.1: Evaluasi Performa Retrieval Model Fine-Tuned ---\")\n",
        "    # Muat FAISS index fine-tuned yang baru dibuat untuk evaluasi\n",
        "    finetuned_faiss_index_for_eval = faiss.read_index(OUTPUT_FAISS_INDEX_FINETUNED)\n",
        "    metrics_finetuned = evaluate_retrieval_performance(\n",
        "        finetuned_embedding_model_instance, finetuned_faiss_index_for_eval, all_processed_chunks_with_metadata,\n",
        "        embedding_evaluation_examples, EVALUATION_TOP_K\n",
        "    )\n",
        "    print(f\"Metrik Model Fine-Tuned: Recall@{EVALUATION_TOP_K}={metrics_finetuned['avg_recall_at_k']:.4f}, MRR@{EVALUATION_TOP_K}={metrics_finetuned['avg_mrr_at_k']:.4f} ({metrics_finetuned['queries_evaluated']} queries)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "529269d6bce5479680715abb1b40d4d7",
            "8b031e2536d54c159f7d2b0de90b9051",
            "0daedc3c6a914b2a996e3e91e6897e87",
            "2a4fe85abe6145cda50cceacc8e421f1",
            "71f46e5360a942dab73205b766b9521f",
            "08207b2e8cbc46b68a1322d5e641c68e",
            "0ccb1089903b4aa9a999fc27d7065539",
            "fdc9f9c009a3484f9b5d1e47f811aa0b",
            "2016615e0f404577a358bce52a7070de",
            "63c33d4d682149daa09e3062577378d3",
            "a5969c842de04f06af992c4d98e67303",
            "4b336787a80042b2bd5752144724b89d",
            "ebbf08d8a9f1457a8e23a88fe2ce08ce",
            "a10f95ada98548b39e423c952974f3cc",
            "d3f4a821389a4281a9e520fed36fe1d5",
            "b462747ab9b643c2a23a9e5f9077cf50",
            "362d8bb1d2024b1ba5de717a9bc73f5b",
            "fecd313a31d5494a882ec6189e3cb064",
            "a0aec6eb1cd04877ab33bd1c71fb2c97",
            "39326c5e3fe14fa2b30c26a7a845a61d",
            "ca4e0554f9944f1988f008445ad48a81",
            "37e6d8e36a74446b9171c90259bc5bae",
            "6cebbe4f213a44bf8e11a8eb8882e52e",
            "14d94fe0f9f640569c15adeb0ac95e1a",
            "6b782f7097d24285ae06615ad53cb49b",
            "e06b447e9d424ac5b36000413282fa79",
            "e68212753b3b4a02a07d2a0a0464de0a",
            "62858c44e11a49b9a3487fd675a0d8a2",
            "aef27301b5014deb807061ec5168f326",
            "e3df7649200e46b2a76e19993b8e8c2a",
            "60ee1018d2b34a50993b13c85dcef6a2",
            "cdfd85ea927048f78e37fe9a5c037a5c",
            "5f3b446677bd4119a3f92cef62f8ec9b"
          ]
        },
        "id": "K19FY6-CEe82",
        "outputId": "ec48267a-d31e-4bd1-bd43-17ba7065b05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Langkah 2: Memuat Dataset Tambahan ---\n",
            "Berhasil memuat 5 contoh dari dataset/SistemOperasi/embedding_finetuning_examples.jsonl untuk fine-tuning embedding.\n",
            "PERINGATAN: File dataset evaluasi 'dataset/SistemOperasi/embedding_evaluation_set.jsonl' tidak ditemukan.\n",
            "\n",
            "--- Langkah 3: Memproses dengan Model Embedding Dasar (all-MiniLM-L6-v2) ---\n",
            "Memulai proses embedding untuk 56 chunk teks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "529269d6bce5479680715abb1b40d4d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses embedding selesai. Dihasilkan 56 embeddings dengan dimensi 384.\n",
            "Membuat FAISS index dengan dimensi 384...\n",
            "FAISS index dengan 56 vektor disimpan ke: dataset/SistemOperasi/vector_store_base.index\n",
            "Semua chunk (56) berhasil disimpan ke: dataset/SistemOperasi/processed_chunks_metadata_base.json\n",
            "\n",
            "--- Langkah 4: Fine-Tuning Model Embedding ---\n",
            "Memulai fine-tuning model embedding 'all-MiniLM-L6-v2'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b336787a80042b2bd5752144724b89d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning selesai dalam 3.08 detik. Model disimpan di: dataset/SistemOperasi/finetuned_embedding_model_sistem_operasi\n",
            "\n",
            "--- Langkah 5: Membuat Artefak RAG Final dengan Model 'dataset/SistemOperasi/finetuned_embedding_model_sistem_operasi' ---\n",
            "Memulai proses embedding untuk 56 chunk teks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cebbe4f213a44bf8e11a8eb8882e52e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses embedding selesai. Dihasilkan 56 embeddings dengan dimensi 384.\n",
            "Membuat FAISS index dengan dimensi 384...\n",
            "FAISS index dengan 56 vektor disimpan ke: dataset/SistemOperasi/vector_store_finetuned.index\n",
            "Semua chunk (56) berhasil disimpan ke: dataset/SistemOperasi/processed_chunks_metadata_finetuned.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- KOMPARASI HASIL EVALUASI ---\n",
        "print(f\"\\n--- Langkah 6: Komparasi Performa Retrieval (Jika Ada) ---\")\n",
        "if metrics_base and metrics_finetuned:\n",
        "    print(f\"Model Dasar ({BASE_EMBEDDING_MODEL_NAME}):\")\n",
        "    print(f\"  Recall@{EVALUATION_TOP_K}: {metrics_base['avg_recall_at_k']:.4f}\")\n",
        "    print(f\"  MRR@{EVALUATION_TOP_K}:    {metrics_base['avg_mrr_at_k']:.4f}\")\n",
        "    print(f\"  ({metrics_base['queries_evaluated']} kueri dievaluasi)\")\n",
        "\n",
        "    print(f\"\\nModel Fine-Tuned ({FINETUNED_EMBEDDING_MODEL_SAVE_PATH}):\")\n",
        "    print(f\"  Recall@{EVALUATION_TOP_K}: {metrics_finetuned['avg_recall_at_k']:.4f}\")\n",
        "    print(f\"  MRR@{EVALUATION_TOP_K}:    {metrics_finetuned['avg_mrr_at_k']:.4f}\")\n",
        "    print(f\"  ({metrics_finetuned['queries_evaluated']} kueri dievaluasi)\")\n",
        "    if metrics_finetuned['avg_recall_at_k'] > metrics_base['avg_recall_at_k']:\n",
        "        print(\"\\nKESIMPULAN: Model Fine-Tuned menunjukkan peningkatan Recall!\")\n",
        "    if metrics_finetuned['avg_mrr_at_k'] > metrics_base['avg_mrr_at_k']:\n",
        "        print(\"KESIMPULAN: Model Fine-Tuned menunjukkan peningkatan MRR!\")\n",
        "elif metrics_base:\n",
        "    print(f\"Hanya metrik model dasar yang tersedia: Recall@{EVALUATION_TOP_K}={metrics_base['avg_recall_at_k']:.4f}, MRR@{EVALUATION_TOP_K}={metrics_base['avg_mrr_at_k']:.4f}\")\n",
        "else:\n",
        "    print(\"Tidak ada metrik evaluasi yang tersedia.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekJb27jXKhZW",
        "outputId": "4ee81297-7be4-4247-a337-78f3638674af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Langkah 6: Komparasi Performa Retrieval (Jika Ada) ---\n",
            "Tidak ada metrik evaluasi yang tersedia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if finetuned_embedding_model_instance is not None:\n",
        "  print(f\"\\n--- Langkah 7: Menyimpan Model Fine-Tuned ---\")\n",
        "  try:\n",
        "    # Model sudah disimpan ke FINETUNED_EMBEDDING_MODEL_SAVE_PATH oleh fungsi finetune_embedding_model\n",
        "    print(f\"Model fine-tuned sudah tersimpan di direktori: {FINETUNED_EMBEDDING_MODEL_SAVE_PATH}\")\n",
        "    # Anda bisa menambahkan verifikasi di sini jika perlu\n",
        "    if os.path.exists(FINETUNED_EMBEDDING_MODEL_SAVE_PATH):\n",
        "        print(\"Direktori model fine-tuned berhasil diverifikasi.\")\n",
        "    else:\n",
        "        print(\"ERROR: Direktori model fine-tuned tidak ditemukan setelah proses fine-tuning.\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error saat mencoba memastikan lokasi model fine-tuned: {e}\")\n",
        "else:\n",
        "  print(\"\\nTidak ada model fine-tuned untuk disimpan tanpa zip (karena fine-tuning dilewati).\")\n",
        "\n",
        "print(\"\\nProses selesai.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GByFKwfLCNo",
        "outputId": "d1bede1b-962d-4596-8939-ced8692c6774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Langkah 7: Menyimpan Model Fine-Tuned ---\n",
            "Model fine-tuned sudah tersimpan di direktori: dataset/SistemOperasi/finetuned_embedding_model_sistem_operasi\n",
            "Direktori model fine-tuned berhasil diverifikasi.\n",
            "\n",
            "Proses selesai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: zip dataset folder\n",
        "\n",
        "# 8. Zip folder dataset\n",
        "print(f\"\\n--- Langkah 8: Meng-zip Folder Dataset ---\")\n",
        "DATASET_FOLDER_TO_ZIP = \"dataset\" # Folder yang akan di-zip\n",
        "DATASET_ZIP_OUTPUT_PATH = \"dataset_zipped_for_download.zip\" # Nama file zip output\n",
        "\n",
        "if os.path.isdir(DATASET_FOLDER_TO_ZIP):\n",
        "    print(f\"Meng-zip folder '{DATASET_FOLDER_TO_ZIP}'...\")\n",
        "    try:\n",
        "        # Hapus file zip lama jika ada\n",
        "        if os.path.exists(DATASET_ZIP_OUTPUT_PATH):\n",
        "            os.remove(DATASET_ZIP_OUTPUT_PATH)\n",
        "            print(f\"File zip dataset lama '{DATASET_ZIP_OUTPUT_PATH}' dihapus.\")\n",
        "\n",
        "        shutil.make_archive(DATASET_ZIP_OUTPUT_PATH.replace('.zip', ''), 'zip', DATASET_FOLDER_TO_ZIP)\n",
        "        print(f\"Folder dataset berhasil di-zip ke: {DATASET_ZIP_OUTPUT_PATH}\")\n",
        "\n",
        "        # Verifikasi bahwa file zip dibuat\n",
        "        if os.path.exists(DATASET_ZIP_OUTPUT_PATH):\n",
        "            print(f\"Ukuran file zip: {os.path.getsize(DATASET_ZIP_OUTPUT_PATH)} bytes\")\n",
        "        else:\n",
        "            print(f\"ERROR: File zip '{DATASET_ZIP_OUTPUT_PATH}' tidak ditemukan setelah proses zip.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat membuat arsip zip folder dataset: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Direktori dataset '{DATASET_FOLDER_TO_ZIP}' tidak ditemukan. Tidak dapat membuat zip.\")\n",
        "\n",
        "print(\"\\nProses selesai.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGl5ac4M_EUx",
        "outputId": "edb96dee-9fb4-44cc-cb0d-6a5cf8910447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Langkah 8: Meng-zip Folder Dataset ---\n",
            "Meng-zip folder 'dataset'...\n",
            "Folder dataset berhasil di-zip ke: dataset_zipped_for_download.zip\n",
            "Ukuran file zip: 83818331 bytes\n",
            "\n",
            "Proses selesai.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "529269d6bce5479680715abb1b40d4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b031e2536d54c159f7d2b0de90b9051",
              "IPY_MODEL_0daedc3c6a914b2a996e3e91e6897e87",
              "IPY_MODEL_2a4fe85abe6145cda50cceacc8e421f1"
            ],
            "layout": "IPY_MODEL_71f46e5360a942dab73205b766b9521f"
          }
        },
        "8b031e2536d54c159f7d2b0de90b9051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08207b2e8cbc46b68a1322d5e641c68e",
            "placeholder": "​",
            "style": "IPY_MODEL_0ccb1089903b4aa9a999fc27d7065539",
            "value": "Batches: 100%"
          }
        },
        "0daedc3c6a914b2a996e3e91e6897e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc9f9c009a3484f9b5d1e47f811aa0b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2016615e0f404577a358bce52a7070de",
            "value": 1
          }
        },
        "2a4fe85abe6145cda50cceacc8e421f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63c33d4d682149daa09e3062577378d3",
            "placeholder": "​",
            "style": "IPY_MODEL_a5969c842de04f06af992c4d98e67303",
            "value": " 1/1 [00:00&lt;00:00,  4.75it/s]"
          }
        },
        "71f46e5360a942dab73205b766b9521f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08207b2e8cbc46b68a1322d5e641c68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ccb1089903b4aa9a999fc27d7065539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdc9f9c009a3484f9b5d1e47f811aa0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2016615e0f404577a358bce52a7070de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63c33d4d682149daa09e3062577378d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5969c842de04f06af992c4d98e67303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b336787a80042b2bd5752144724b89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebbf08d8a9f1457a8e23a88fe2ce08ce",
              "IPY_MODEL_a10f95ada98548b39e423c952974f3cc",
              "IPY_MODEL_d3f4a821389a4281a9e520fed36fe1d5"
            ],
            "layout": "IPY_MODEL_b462747ab9b643c2a23a9e5f9077cf50"
          }
        },
        "ebbf08d8a9f1457a8e23a88fe2ce08ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362d8bb1d2024b1ba5de717a9bc73f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_fecd313a31d5494a882ec6189e3cb064",
            "value": "Computing widget examples:   0%"
          }
        },
        "a10f95ada98548b39e423c952974f3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0aec6eb1cd04877ab33bd1c71fb2c97",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39326c5e3fe14fa2b30c26a7a845a61d",
            "value": 1
          }
        },
        "d3f4a821389a4281a9e520fed36fe1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca4e0554f9944f1988f008445ad48a81",
            "placeholder": "​",
            "style": "IPY_MODEL_37e6d8e36a74446b9171c90259bc5bae",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "b462747ab9b643c2a23a9e5f9077cf50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "362d8bb1d2024b1ba5de717a9bc73f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fecd313a31d5494a882ec6189e3cb064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0aec6eb1cd04877ab33bd1c71fb2c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39326c5e3fe14fa2b30c26a7a845a61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca4e0554f9944f1988f008445ad48a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e6d8e36a74446b9171c90259bc5bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cebbe4f213a44bf8e11a8eb8882e52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14d94fe0f9f640569c15adeb0ac95e1a",
              "IPY_MODEL_6b782f7097d24285ae06615ad53cb49b",
              "IPY_MODEL_e06b447e9d424ac5b36000413282fa79"
            ],
            "layout": "IPY_MODEL_e68212753b3b4a02a07d2a0a0464de0a"
          }
        },
        "14d94fe0f9f640569c15adeb0ac95e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62858c44e11a49b9a3487fd675a0d8a2",
            "placeholder": "​",
            "style": "IPY_MODEL_aef27301b5014deb807061ec5168f326",
            "value": "Batches: 100%"
          }
        },
        "6b782f7097d24285ae06615ad53cb49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3df7649200e46b2a76e19993b8e8c2a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60ee1018d2b34a50993b13c85dcef6a2",
            "value": 1
          }
        },
        "e06b447e9d424ac5b36000413282fa79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdfd85ea927048f78e37fe9a5c037a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_5f3b446677bd4119a3f92cef62f8ec9b",
            "value": " 1/1 [00:00&lt;00:00,  5.09it/s]"
          }
        },
        "e68212753b3b4a02a07d2a0a0464de0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62858c44e11a49b9a3487fd675a0d8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef27301b5014deb807061ec5168f326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3df7649200e46b2a76e19993b8e8c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ee1018d2b34a50993b13c85dcef6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdfd85ea927048f78e37fe9a5c037a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f3b446677bd4119a3f92cef62f8ec9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}